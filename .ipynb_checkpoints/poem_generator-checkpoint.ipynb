{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poems Generator using Word Embeddings\n",
    "\n",
    "\n",
    "First we load all the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as  np\n",
    "import re\n",
    "import spacy\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data recollection\n",
    "We collect Edgar Allan Poe poems from the **mypoeticside.com** site and save then into a *.csv* file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this trick the server to think that we are connecting from a web browser\n",
    "class AppURLopener(urllib.request.FancyURLopener): \n",
    "    version = \"Mozilla/5.0\" \n",
    "opener = AppURLopener()\n",
    "writer = \"edgar-allan-poe-poems\"\n",
    "data = opener.open('https://mypoeticside.com/poets/' + writer).read().decode()\n",
    "\n",
    "#search and save the poem links \n",
    "soup =  BeautifulSoup(data, 'html.parser')\n",
    "poem_list = soup.find(class_=\"list-poems\")\n",
    "links = poem_list.findAll('a')\n",
    "results = [\"https:\"+link.get('href') for link in links]\n",
    "\n",
    "#saves the title and content of each poem\n",
    "titles = []\n",
    "corpus = []\n",
    "for page in results:\n",
    "     data = opener.open(page).read().decode()\n",
    "     soup = BeautifulSoup(data, 'html.parser')\n",
    "     title = soup.find(class_='title-poem')\n",
    "     poem = soup.find(class_='poem-entry')\n",
    "     titles.append(title.getText())\n",
    "     print(title.getText())\n",
    "     corpus.append(poem.find('p').getText())\n",
    "     \n",
    " #saves to a .csv file all the poems   \n",
    "poems = pd.DataFrame({'title' : titles,'text' : corpus})\n",
    "poems.to_csv('allan_poems.csv')\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning and preparation\n",
    "We split the poems into sentences, replace unwanted characters and save everytihn into a new *.csv* file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def docs_to_sentences(file, split=r\"\\n\"):\n",
    "    path = os.getcwd()\n",
    "    df_docs = pd.read_csv(path+\"/\" + file)\n",
    "    number_docs = df_docs.shape[0]\n",
    "    df_sentences = pd.DataFrame(columns=['doc_id','sentence'])  \n",
    "    for i in range(number_docs):\n",
    "        text = df_docs.text[i]\n",
    "        #dictionary to replace unwanted elements\n",
    "        replace_dict = {'?«' :  '«', '(' :  '', ')' : '', ':' : ',', '.' : ',', ',,,' : ',', '\"':''}\n",
    "        for x,y in replace_dict.items():\n",
    "            text = text.replace(x, y)\n",
    "        text = text.lower()   \n",
    "        #split into sentences\n",
    "        sentences = re.split(split, text)\n",
    "        len_sentences = len(sentences)   \n",
    "        doc_id = [i] * (len_sentences)\n",
    "        #save sentence and poem_id\n",
    "        doc_sentences = pd.DataFrame({'doc_id' : doc_id, 'sentence' : sentences})\n",
    "        df_sentences = df_sentences.append(doc_sentences)   \n",
    "    #extra cleaning and reset index\n",
    "    df_sentences = df_sentences[df_sentences.sentence != '']\n",
    "    df_sentences.reset_index(drop=True, inplace=True)  \n",
    "    #saves clean sentences to a .csv file \n",
    "    df_sentences.to_csv(\"sentences_\" + file)\n",
    "    \n",
    "docs_to_sentences('allan_poems.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## poem generator function\n",
    "We define the generator function which takes 3 arguments: the sentences file, the initial word and the number of verses for the new poem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poem_generator(file, word, n_sents=4):\n",
    "        #load the english model from Spacy\n",
    "        nlp = spacy.load(\"en\")\n",
    "        init_str = nlp(word)\n",
    "        path = os.getcwd()\n",
    "        sentences = pd.read_csv(path+'/'+ file)\n",
    "        sup_index= sentences.shape[0]\n",
    "        poem_id = int()\n",
    "        poem =[]\n",
    "        #generate the sentences\n",
    "        for i in range(n_sents):\n",
    "            rand_sent_index = np.random.randint(0, sup_index, size=30)\n",
    "            sent_list = list(sentences.sentence.iloc[rand_sent_index])\n",
    "            #transform sentences to a Spacy Doc object\n",
    "            docs = nlp.pipe(sent_list)\n",
    "            sim_list = []\n",
    "            #compute similarity for each sentence\n",
    "            for sent in docs:\n",
    "                similarity = (init_str.similarity(sent))\n",
    "                sim_list.append(similarity)\n",
    "            #saves similarity to DataFrame\n",
    "            df_1 = pd.DataFrame({'similarity' : sim_list, 'doc_id' : sentences.doc_id.iloc[rand_sent_index] }, index=rand_sent_index)   \n",
    "            df_1 = df_1[df_1.doc_id != poem_id]\n",
    "            df_1.sort_values(by='similarity', inplace=True, ascending=False)\n",
    "            sent_index= df_1.index[0]\n",
    "            sent = sentences.sentence[sent_index]\n",
    "            #erase line jumps and carriage return\n",
    "            replace_dict = {'\\n' :  '', '\\r' :  ''}\n",
    "            for x,y in replace_dict.items():\n",
    "                sent = sent.replace(x, y)\n",
    "            poem.append(sent)    \n",
    "            poem_id = df_1.doc_id.iloc[0]\n",
    "            init_str = nlp(sent)  \n",
    "        #join the sentences with a line break\n",
    "        str_poem = (\"\\n\".join(poem)) \n",
    "        return str_poem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## poem formating function\n",
    "Finally we define a function to uppercase the first letter and add a dot and the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_poem(text):\n",
    "    text = text[:1].upper() + text[1:]\n",
    "    text = text[:-1] + '.'\n",
    "    return text "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          and true love caresses-\n",
      "           and i rest so contentedly,\n",
      "     methought, my sweet one, then i ceased to soar\n",
      "     i would not call thee fool, old man.\n"
     ]
    }
   ],
   "source": [
    "# example n° 1\n",
    "poem = poem_generator(file='sentences_allan_poems.csv',word='love')\n",
    "poem = format_poem(poem)\n",
    "print(poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
